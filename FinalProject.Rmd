---
title: 'Final Project: Guidance Document'
author: "Allen,Julian,Vishnu,Shweta"
date: "Due December 3, 2023"
output:
  html_notebook: default
  pdf_document: default
  html_document:
    df_print: paged
---

# Purpose

*This document is required to indicate where various requirements can be found within your Final Project Report Rmd.  You must* **indicate line numbers as they appear in your final Rmd document** *accompanying each of the following required tasks. Points will be deducted if line numbers are missing or differ signficantly from the submitted Final Rmd document.*  


# Final Project Requirements


### Data Access

*Description: (1) Analysis includes at least two different data sources. (2) Primary data source may NOT be loaded from an R package--though supporting data may. (3) Access to all data sources is contained within the analysis. (4) Imported data is inspected at beginning of analysis using one or more R functions: e.g., str, glimpse, head, tail, names, nrow, etc*

(A) .Rmd Line numbers where at least two different data sources are imported:  
```{r}
rm(list = ls())
library(rvest)
library(lubridate)
library(tidyverse)
library(DataComputing)
#data("SanFranPublicBathrooms.csv")

sanfran=read.csv("SanFranPublicBathrooms.csv", header=TRUE)
head(sanfran)

library(remotes)
install_github("yonghah/esri2sf")
library("esri2sf")
url <- "https://services.arcgis.com/QPnoxtBFXm6yYtyc/ArcGIS/rest/services/SanFranciscoPoopMap_WFL1/FeatureServer/2"
poop <- esri2sf(url, objectIds = paste(collapse = ","))
```


(B) .Rmd Line numbers for inspecting data intake:  
```{r}
str(poop)
head(sanfran)
```


### Data Wrangling (5 out of 8 required)

*Description: Students need not use every function and method introduced in STAT 184, but clear demonstration of proficiency should include proper use of 5 out of the following 8 topics from class: (+) various data verbs for general data wrangling like filter, mutate, summarise, arrange, group_by, etc. (+) joins for multiple data tables. (+) spread & gather to stack/unstack variables (+) regular expressions (+) reduction and/or transformation functions like mean, sum, max, min, n(), rank, pmin, etc. (+) user-defined functions (+) loops and control flow (+) machine learning*


(A) .Rmd Line number(s) for general data wrangling: 
```{r}
wrangled<-
  poop%>%
  mutate(URL=NULL)



```


(B) .Rmd Line number(s) for a join operation: 
```{r}
poopAtRestroom<-
  left_join(wrangled, sanfran, by=c('Neighborhood'='analysis_neighborhood'))

head(poopAtRestroom)
```


(C) .Rmd Line number(s) for a spread or gather operation (or equivalent):
```{r}
  availaibility<-
    poopAtRestroom%>%
    group_by(access)%>%
    summarise(poops=n_distinct(OBJECTID))
  availaibility
```


(D) .Rmd Line number(s) for use of regular expressions: 
Note: part F has the regular expression
```{r}
Matches <- street_ending_finder(poop, poop$Address, "ST")
Matches
```

(E) .Rmd Line number(s) for use of reduction and/or transformation functions: 

```{r}

x <- wrangled %>%
  select(Neighborhood) %>%
  group_by(Neighborhood) %>%
  summarise(poop_count=n())

y <- sanfran %>%
  select(analysis_neighborhood) %>%
  group_by(analysis_neighborhood) %>%
  summarise(restroom_count=n())

joined_table <- x %>% 
  full_join(y, join_by("Neighborhood" == "analysis_neighborhood"))

joined_table <- joined_table[!is.na(joined_table$Neighborhood),]


```

(F) .Rmd Line number(s) for use of user-defined functions: 
```{r}
street_ending_finder=function(frame, street.col, street.ending){
  pattern <- paste(street.ending, "$", sep="")
  pattern
  Matches <- frame %>%
    filter(grepl(pattern = pattern, street.col, ignore.case = TRUE))
  return(Matches)
}


convert_num_to_date = function(date){
  hours_passed = (date %% 39630) * 2
  days = hours_passed %/% 24
  days
}

poop2 <- poop %>% mutate(convert_num_to_date(poop$Date))
```

(G) .Rmd Line number(s) for use of loops and/or control flow: 
```{r}





for (i in 1:length(joined_table$Neighborhood)){
  case <- joined_table[i,]
  for (j in 1:length(case)){
    variable <- joined_table[i,j]
    if (is.na(variable) ){
      joined_table[i,j] <- 0
    }
  }
}


```
(H) .Rmd Line number(s) for use of machine learning (not "wrangling" but scored here): 

We want to explore if a restroom count in a neighborhood has an effect on poop count
in a neighborhood. We will use linear regression to explore this. 

The setup:

$poop\_count_i \sim N(b_0 + b_1 \times restroom\_count_i, \sigma^2)$


The following Hypothesis are used:

\begin{align*}
H_0 &: b_1 = 0 \\
H_a &: b_1 \neq 0
\end{align*}


Approach taught in Stat 415, write a negative log liklihood function.

```{r}

nll.regression = function(theta, poop_count, restroom_count){
  b0 = theta[1]
  b1 = theta[2]
  sigma_sq = theta[3]
  mean = b0 + b1 * restroom_count
  -sum(dnorm(poop_count, mean=mean, sd = sigma_sq, log = TRUE))
}


```


Here we use the optim function which will estimate the MLE for $ b_0, b_1$ and $\sigma^2$
```{r}
out = optim(c(0, 0, 1), nll.regression, poop_count=joined_table$poop_count, restroom_count=joined_table$restroom_count, hessian=TRUE)


b1= out$par[2]
I = out$hessian

se = sqrt(diag(solve(I)))

```

Calculate the Wald-Test Statistic and check $P(|Z^*| < 0.05)$

```{r}
Z = (b1 - 0)/se[2]

p_val = 2 * dnorm(-abs(Z))

p_val


```
Since our p_value is less than 0.05, we can reject our null hypothesis and conclude that
the number of restrooms in an area has an effect on the number of poops in that area

### Data Visualization (3 of 4 required)

*Description: Students need not use every function and method introduced in STAT 184, but clear demonstration of proficiency should include a range of useful of data visualizations that are (1) relevant to stated research question for the analysis, (2) include at least one effective display of many--at least 3--variables, and (3) include 3 of the following 5 visualization techniques learned in STAT 184: (+) use of multiple geoms such as points, density, lines, segments, boxplots, bar charts, histograms, etc (+) use of multiple aesthetics--not necessarily all in the same graph--such as color, size, shape, x/y position, facets, etc (+) layered graphics such as points and accompanying smoother, points and accompanying boxplots, overlaid density distributions, etc  (+) decision tree and/or dendogram displaying machine learning model results*


(A) .Rmd Line number(s) for use of mulitple different geoms:  

```{r}
b0 = out$par[1]
b1 = out$par[2]

reg_func = function(b0, b1, x){
  b0 + b1 * x
}

ggplot(joined_table) + geom_point(aes(x = restroom_count, y = poop_count)) + 
  geom_line(aes(x = restroom_count, y = reg_func(b0, b1, restroom_count), color = "red"))
```

(B) .Rmd Line number(s) for use of multiple aesthetics:  

(C) .Rmd Line number(s) for use of layered graphics:  

(E) .Rmd Line number(s) for use of decision tree or dendogram results:    



Part C
```{r}
# devtools::install_github("rstudio/leaflet")

library(leaflet)

Poop_Map <- 
   leaflet() %>%
  addTiles() %>%
   addMarkers(clusterOptions = markerClusterOptions(), data=poop) %>%
   addCircleMarkers(radius=2, color="red", data=sanfran) %>%
   setView(-122.44, 37.76849, zoom=12)%>% 
   addLegend(position = "bottomleft",
                         colors = c("red", "orange"),
                         labels = c("Public_Restrooms", "Poop Clusters are numbered"),
                         title = "Marker Categories")

Poop_Map
```

### Other requirements (Nothing for you to report in this Guidance Document)

(A) *All data visualizations* must be relevant to the stated research question, and the report must include at least one effective display of many--at least 3--variables 

(B) *Code quality:* Code formatting is consistent with Style Guide Appendix of DataComputing eBook. Specifically, all code chunks demonstrate proficiency with (1) meaningful object names (2) proper use of white space especially with respect to infix operators, chain operators, commas, brackets/parens, etc (3) use of `<-` assignment operator throughout (4) use of meaningful comments.

(C) *Narrative quality:* The narrative text (1) clearly states one research question that motivates the overall analysis, (2) explains reasoning for each significant step in the analysis and it's relationship to the research question, (3) explains significant findings and conclusions as they relate to the research question, and (4) is completely free of errors in spelling and grammar

(D) *Overall Quality:* Submitted project shows significant effort to produce a high-quality and thoughtful analysis that showcases STAT 184 skills. (2) The project must be self-contained, such that the analysis can be entirely rerun without errors. (3) Analysis is coherent, well-organized, and free of extraneous content such as data dumps, unrelated graphs, and other content that is not overtly connected to the research question.

(E) *EXTRA CREDIT* (1) Project is submitted as a self-contained GitHub Repo (2) project submission is a functioning github.io webpage generated for the project Repo. Note: a link to the GitHub Repo itself will be awarded partial credit, but does not itself qualify as a "webpage" of the analysis.





